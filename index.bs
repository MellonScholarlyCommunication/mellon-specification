<pre class='metadata'>
Title: Use Cases and Requirements for the Mellon Project
Shortname: ldnp-req
Level: 1
Max ToC Depth: 3
Status: w3c/ED
Group: UGent-Imec
URL: 
Editor: Ruben Dedecker (UGent - Imec)
Markup Shorthands: markdown yes
Abstract:
  Use Cases and Requirements for the Mellon Project.
</pre>

<!-- For bikeshed style overrides -->
<style>

  table.collections thead tr {
    font-size: 16px;
  }

  table.collections tbody tr:nth-child(even) {
    background-color: lightgray;
    font-size: 12px;
  }

  @media (prefers-color-scheme: dark) {
    table.collections tbody tr:nth-child(even) {
      background-color: DarkSlateGray;
    }
  }

  table.collections tbody td {
    font-size: 12px;
  }

  figcaption {
    text-align: left;
  }

  a[data-link-type=dfn] {
    color: #000000;
  }

  @media (prefers-color-scheme: dark) {
    a[data-link-type=dfn] {
      color: #FFFFFF;
    }
  }

}

</style>

<div boilerplate="copyright">
MIT License Copyright 2019 - 2020 UGent - Imec
</div>

Introduction {#intro}
================================================================================
The goal of the mellon project is to design a framework that enables scholarly communication over a decentralized network, where researchers can retain ownership and control over their published research.
In order to design this framework, different approaches to distributed networks have to be considered, and technical limitations have to be overcome.

In [[#scholarly-communication]], the requirements and vision for scholarly communication are explained.
In [[#architecture]], an architecture is proposed for scholarly communication over decentralized networks based on pod based data storage.
The artefacts required for scholarly communication are listed in [[$artefacts]].
For the proposed architecture, concrete use-cases are worked out in [[#usecases]].
From these use-cases, requirements are derived in [[#requirements]].


Scholarly communication {#scholarly-communication}
================================================================================

## Core functions of scholarly communication ## {#functions-scholarly-communication}
For scholarly communication to be successful, [four core functions](http://www.dlib.org/dlib/september04/vandesompel/09vandesompel.html) have to be fulfilled.
<table style="width:100%">
  <tr style="border-bottom: 1px solid #000;">
    <th style="width: 20%; padding-top: 10px; padding-bottom: 15px;">Function</th> 
    <th style="padding-top: 10px; padding-bottom: 15px;">Explanation</th>
  </tr>
  <tr>
    <th>Registration</th>
    <td>Allowing claims of precedence for a scholarly finding</td>
  </tr>
  <tr>
    <th>Certification</th> 
    <td>Establishing the validity of a registered scholarly claim</td>
  </tr>
  <tr> 
    <th>Awareness</th> 
    <td>Enabling actors in the scholarly system to remain aware of new claims and findings</td>
  </tr>
  <tr>
    <th>Archiving</th> 
    <td>Preserving the scholarly record over time</td>
  </tr>
</table>

These four functions are required in the network to be able to do scholarly communication.
In the context of a decentralized network, registration can also be viewed as a way to link researchers to their institutions, allowing for trust in the validity of the researcher and their research.

## Researcher-centric scholarly communication model ## {#research-centric-model}
The goal is that researchers’ pods are hosted by their respective institutions, as part of the infrastructure provided in support of research and education. When a researcher moves on to another institution, the pod moves along and becomes hosted by the new institution. Researchers without institutional affiliation or with multiple affiliations can opt for commercial pod hosting platforms, national/regional academic hosting provisions that can be assumed to emerge, or host the pod themselves. Over time, a researcher’s pod accumulates an overview of scholarly contributions made throughout a career path. 

## The role of institutions in a decentralized scholarly communication network ## {#institutions-decentralized-network-trust}
As decentralized networks do not have a single central service that actors can trust, actors in the network require an approach that allows them to trust other actors present in the network.

In these networks, institutions can take on the role as the orchestrators of a decentralized scholarly communication network.
These orchestrators connect the registered researcher pods with the available service hubs in the network, and serve as a trusted mediator between the researchers and the service hubs.
Service hubs can trust all researcher pods registered to / making use of a trusted orchestrator (managed by an institution), as they trust that every researcher pod registered to / using that orchestrator is managed by a person affiliated with the managing institution of that orchestrator.
In the other direction, researchers registering their pods to / using the orchestrator managed by their institution trust the service hubs advertised by that orchestrator.
In the case of problems, the institution can change from / advertise multiple different service hubs, by changing the policies.

This way, institutions actively participate in the decentralized network of scholarly communication as orchestrators and trusted parties.


Architecture of a Decentralized Network for Scholarly Communication {#architecture}
================================================================================

<figure>
	<img src="images/ecosystem.png" />
	<figcaption>A decentralized, decoupled scholarly communication ecosystem with researcher pod, scholarly dashboard, orchestrator, Service Hubs, scholarly browser. </figcaption>
</figure>



## Researcher pod ## {#researcher-pod}
The researcher pod serves as the main hub for a researcher, serving as a storage module for scholarly artefacts and interactions, and for exchanging information with external service providers and institutions.


A researcher pod stores the following information:

<table style="width:100%">
  <tr style="border-bottom: 1px solid #000;">
    <th style="width: 20%; padding-top: 10px; padding-bottom: 15px;">Information type</th> 
    <th style="padding-top: 10px; padding-bottom: 15px;">Explanation</th>
  </tr>
  <tr>
    <th>Personal contributions</th>
    <td>Scholarly contributions (artifacts and interaction artifacts) made by the researcher and descriptive metadata for them. This information is recorded using the researcher’s preferred authoring applications</td>
  </tr>
  <tr>
    <th>Functions of scholarly communication</th> 
    <td>Lifecycle event metadata pertaining to the fulfillment of the functions of scholarly communication for the researcher’s personal contributions. Through the intermediation of the Orchestrator, this information is obtained via Service Hubs of platforms that fulfil the respective functions</td>
  </tr>
  <tr>
    <th>Peer contributions</th> 
    <td>Pertinent metadata about selected interaction artifacts created by peers and pertaining to the researcher’s personal contributions. This information is obtained via an Awareness Service Hub (the one used for the interaction artifact) through the intermediation of the peers’ Orchestrator</td>
  </tr>
  <tr>
    <th>Social interactions</th> 
    <td>A record of the informal interactions the researcher has with peers via available social network features that are enabled by solid pods</td>
  </tr>
</table>

## Orchestrator (managed by Institutions) ## {#orchestrator}
Institutions participate in the decentralized scholarly communication network by providing orchestrator services to the network. In this way, an institution can manages their affiliated researchers using these orchestrators. 
The orchestrators connect researcher pods with a relevant set of service hubs that enable the researcher pod to fulfill all the [functions of scholarly communication](#functions-scholarly-communication) 
In its role as an orchestrator, it can set policies that are enforced in the communication between the research pods and the service hubs.

Orchestrators should be linked to institutions to allow for [trust based operating of the network](#institutions-decentralized-network-trust).

## Service hubs ## {#service-hub}
Service hubs provide services to the network.
These services are necessary to enable the execution of the [functions of scholarly communication](#functions-scholarly-communication) by the network.
Service hubs are a way to decentralize the functionality that is currently primarily contained to centralized services.
Orchestrators have a choice between all the available service hubs in the network to, and can require one (or multiple) of the available service hubs to be used by the affiliated researcher pods to fulfill a function of scholarly communication.

## Collector ## {#collector}
A Collector is a service that collects and indexes information on the artefacts in the network.
It collects this information from the available service hubs in the network. (It might make sense to also allow collectors to retrieve information directly from researcher pods. Else the interaction artefacts have to pass through a service hub that can be retrieved by a collector in the network. Also it can bypass service hubs if they are not willing to provide all required information themselves / only partly).
It stores information about the available artefacts, and the linked lifecycle events and interaction artefacts.
The collector provides an outward API that enables querying of the artefact information in the network. It can also provide indexing information to enable clients to filter over the exposed data. (This might be an interesting use case for event streams!).
In the case of multiple distributed networks, collectors can collect data from / refer to other collectors in other networks to enable evaluating queries over all linked networks.

## Scholarly Dashboard ## {#scholarly-dashboard}
The scholarly dashboard is the interface that can be used by researchers to execute the lifecycle events of an artefact (publish an artefact, review an artefact, interact with an artefact, ...)
(This dashboard may also include functionality for direct interactions between researchers, however this is out of scope for a basis scholarly dashboard).
A scholarly dashboard can be managed by an institution, requiring users to provide login credentials of said institution. (or be from external parties providing other possibilities / interactions?)

## Scholarly Browser ## {#scholarly-browser}
The scholarly browser is the interface that can be used by anyone to query the distributed network for information on scholarly artefacts.
It provides information about the artefact, as well as lifecycle events and the available interactions with the artefact.


Artefacts of scholarly communication {#artefacts-scholarly-communication}
================================================================================
The functions of scholarly communication produce artefacts.
These artefacts need to be stored on the relevant locations, and should be retrievable by the appropriate actors to fulfil the functions of scholarly communication.


## Artefacts ## {#artefacts}
The artefacts of scholarly communication that are to be stored in the decentralized network.
In this section, the artefacts stored and generated by the network are listed and explained.

### Research Artefacts ### {#research-artefacts}
These artefacts are the result of research done by a researcher.

(This list is non-exhaustive)

<table style="width:100%">
  <caption>Research artefacts</caption>
  <tr>
    <th style="width: 20%; padding-top: 10px; padding-bottom: 15px;"></th> 
    <th style="padding-top: 10px; padding-bottom: 15px;"></th>
  </tr>
  <tr>
    <td>Paper (preprint)</td> 
    <td>A research paper (preprint) and the corresponding metadata.</td> 
  </tr>
  <tr>
    <td>Supporting data</td> 
    <td>Images, datasets, software, ..., supporting the research and their respective metadata</td> 
  </tr>
  <tr>
    <td>Research objects</td> 
    <td>Research objects ([Research Object Crates](http://www.researchobject.org/ro-crate/)) is an approach to packaging research data and metadata. 
    This may be useful to create a unified semantic layer over published components of research.</td> 
  </tr>
</table>



### Interaction Artefacts ### {#interaction-artefacts}
These artefacts are the result of interactions on artefacts by actors in the network.

(This list is non-exhaustive)

<table style="width:100%">
  <caption>Interaction artefacts</caption>
  <tr>
    <th style="width: 20%; padding-top: 10px; padding-bottom: 15px;"></th> 
    <th style="padding-top: 10px; padding-bottom: 15px;"></th>
  </tr>
  <tr>
    <td>Comment</td> 
    <td>A comment made on an artefact in the network and its metadata (creator, timestamp, ...)</td> 
  </tr>
  <tr>
    <td>Proposed edit</td> 
    <td>A proposed edit on an artefact in the network and its metadata</td> 
  </tr>
  <tr>
    <td>Review</td> 
    <td>A review by an actor in the network of a research artefact in the network.</td> 
  </tr>
</table>

### Artefact Lifecycle Events ### {#lifecycle-events}
Artefact lifecycle events provide metadata over the events that happen in the lifecycle of an artefact.
This metadata enables actors in the network to follow the events in the artefact lifecycle step by step, and to retrieve all information relevant to the artefact.

<table>
  <caption>Artefact lifecycle events</caption>
    <td>Creation</td> 
    <td>The creation of a research project (with initial data?) by an actor in the network.</td> 
  </tr>
  <tr>
    <td>Publication</td> 
    <td>The publication of research (in the form of a paper publication / research object / ...) by an actor (individual researcher / institution / ...) in the network</td> 
  </tr>
  <tr>
    <td>Review</td> 
    <td>An artefact in the network has been reviewed by an actor in the network</td> 
  </tr>
  <tr>
    <td>Update</td> 
    <td>An artefact in the network has been updated by an actor in the network</td> 
  </tr>
  <tr>
    <td>Reference</td> 
    <td>An artefact in the network has been referenced by another artefact in the network</td> 
  </tr>
  <tr>
    <td>Subscription</td> 
    <td>An actor in the network has subscribed to an artefact in the network</td> 
  </tr>
  <tr>
    <td>Interactions</td> 
    <td>An actor in the network has interacted with an artefact in the network.</td> 
  </tr>
</table>




<figure>
	<img src="images/artefactmetadata.png" />
	<figcaption>artifacts, interaction artifacts, descriptive metadata, event metadata</figcaption>
</figure>


## Subscribing to artefacts in the network ## {#subscribable-entities}
Actors inside (and outside) the network may be interested in following specific research topics, authors, ... .
This is a core function of scholarly communication: [Awareness](#functions-scholarly-communication).
For scholarly communication, it should be possible to subscribe on all lifecycle events of artefacts in the network (for which an actor has the correct permissions).
This can be handled by the available [Service Hubs for awareness](#service-hub) present in the network. [Collectors](#collector) present in the network can also pose as an awareness service hub, as it indexes lifecycle information of all artefacts present in the network
These [Service Hubs for awareness](#service-hub) should be equipped to enable actors in the network to subscribe to specific lifecycle information for research artefacts that match given filter criteria.
E.g. an actor should be able to subscribe to creation lifecycle events of artefacts tagged with "Scholarly Communication".
The service hub should be able to advertise the available options for filtering research, and the lifecycle information which can be subscribed to.



Policies {#policies}
================================================================================
Policies must be enforcable in the network to enforce the policies present in the research institutions. There are different actors in the network that can enforce different kinds of policies.


## Researcher pod policies ## {#researcher-pod-policies}
The researcher has full control over his researcher pod.
Because of this, the researcher can set policies that must be adhered to for their own data pod.
An example of this is providing shape trees that enforce where certain data must be stored on the pod (interaction artefacts, lifecycle information, ...).
Because of these policies, it is important that all information submitted from a researcher pod is also stored and archived by the service hubs, as the policies set by a data pod may reject certain data from being stored on the pod.

## Orchestrator policies ## {#orchestrator-policies}
The orchestrators in the network serve as the mediators between the researcher pods and the service hubs in the network.
Because of this position, the orchestrator can enforce policies on the data being submitted from the researcher pods to the service hubs.
Examples of enforceable policies are requiring artefacts to be peer reviewed before certification, requiring all artefact metadata to be present before submitting to services,  advertising / enforcing certain service hubs, ...)
The orchestrator policies are set by the institution managing the orchestrator.

## Scholarly Dashboard policies ## {#scholarly-dashboard-policies}
The scholarly dashboard can enforce it's own set of policies.
It can enforce the orchestrators that are used, decide on data formats, ...
These policies can be essential to the correct working of the dashboard (e.g. require specific data formats to show statistics, edit artefacts, ...). 
The scholarly dashboard policies are set by the institution managing the scholarly dashboard.


## Service hub policies ## {#service-hub-policies}
Service hubs may also enforce policies on the received submission.
E.g. they may require all metadata to be filled out for a submitted artefact, or require a specific file format for submissions.
Ideally these policies should be also enforced by the scholarly dashboard / orchestrator making use of the service.
The service hub policies are set by the institution or third party managing the service hub.



Use Cases {#usecases}
================================================================================

## Joining a scholarly communication network ## {#joining-scholarly-communication-network}
In order to create or interact with artefacts in a scholarly communication network, a user must have a valid data pod environment to store these (interaction) artefacts.
In order for these artefacts to be taken into the scholarly record, they have to be passed to the respective service hubs that fulfil these functions.
For this to be possible, the data pod must have access to an orchestrator in the network, that will ensure that the created artefacts can follow the correct steps to be included in the scholarly record.

### Creating a data pod ### {#uc-create-pod}
Bob wants to interact with published artefacts in the network, but does not have a data pod available to store these interactions.
Any [scholarly dashboard](#scholarly-dashboard) used to interact with artefacts in the network SHOULD provide an option to login to an existing pod, register an existing data pod or to create a new data pod.
Bob chooses the option to create a new pod, and is redirected to an environment where he can create a new data Pod (The available environments can be selected by the scholarly dashboard, as the use of specific platforms can be advertised / enforced).

### Participating in the network with an existing data pod ### {#uc-participate-network}
Bob wants to interact with published artefacts in the network, and has a data pod available.
Bob chooses the option of the [scholarly dashboard](#scholarly-dashboard) to login with an existing data pod.
The institution managing the scholarly dashboard MAY require Bob to authenticate himself to the institution before allowing use of the dashboard.
On authentication, Bob is given access to the functionality available in the scholarly dashboard, and interactions in with artefacts may be handled by an orchestrator already linked in the Bob's pod, or by an orchestrator advertised / enforced by the scholarly dashboard.


## The researcher profile ## {#uc-profile}
On initial participation in a scholarly communication network, actors in the network MAY enforce that connecting data pods require a researcher profile to be complete, in order to validate affiliations to certain institutions.
Any [scholarly dashboard](#scholarly-dashboard) used to interact with the scholarly communication network SHOULD provide functionality / redirect to services for researchers to create their profile.
Institutions SHOULD provide functionality for researchers to receive a token of sorts proving their affiliation to the institution, that can be used by actors in the network to verify the researcher's affiliations.

### Creating a researcher profile ### {#uc-create-researcher-profile}
Bob logs on to a [scholarly dashboard](#scholarly-dashboard) with a newly created data pod by authenticating himself to the dashboard.
The dashboard analyses Bob's data pod, and cannot discover a researcher profile.
The dashboard SHOULD provide a way for Bob to create a researcher profile / the dashboard can create a researcher profile automatically if it has the available information using Bob's authentication to the dashboard.
Bob's researcher profile is now added to Bob's data pod, and is passed to one or more orchestrators in the network (connected to Bob's data pod or to the scholarly browser).
The orchestrators make sure that the information is passed to the relevant services, so that Bob's updated information is now available in the network.

### Updating a researcher profile ### {#view-profile}
Bob has changed jobs and now works at a new research institution.
The Scholarly Dashboard of the new institution SHOULD provide functionality for Bob to update his researcher profile. 
On submission of the new information, it is passed to one or more orchestrators in the network (connected to Bob's data pod or to the scholarly browser).
The orchestrators make sure that the information is passed to the relevant services, so that Bob's updated information is now available in the network.




## Uploading artefacts ## {#uc-upload-artefact}
Here we present some use-cases for adding artefacts to the network.

### Adding artefacts to the network ### {#uc-add-artefact}
Bob has created a new research paper.
Bob wishes to add the artefact to the network.
Bob opens the scholarly dashboard, and navigates to the upload section.
Bob selects the artefact he wishes to add, and completes all required information that cannot be automatically extracted from the uploaded artefact.
On submission, the scholarly dashboard stores the artefact in the data pod of Bob on the designated location (designated by Bob, or designated by the shape tree present in the pod).
The scholarly dashboard receives the information for all relevant service hubs from the orchestrator.
The artefact data is sent to all relevant service hubs (At least the registration service hub for claims of precedence).
The created lifecycle events are stored on Bob's data pod, and are distributed to all subscribed actors in the network via the awareness service hub.

### Linking new artefacts to existing artefacts in the network ### {#uc-link-artefact}
Bob wishes to add relevant datasets for a previous published paper (by him) in the network.
In the case the published paper is not his, an approach is needed that allows the original creator of the linked artefact to accept the new link.
Bob opens the scholarly dashboard, and navigates to the upload view.
Bob uploads the new artefact.
Bob selects the artefact that the new artefact is linked to in a "Link" section of the view.
On submission, the scholarly dashboard stores the artefact in the data pod of Bob on the designated location (designated by Bob, or designated by the shape tree present in the pod).
The scholarly dashboard receives the information for all relevant service hubs from the orchestrator.
The artefact data is sent to all relevant service hubs.


## Interacting with artefacts in the network ## {#uc-interact-artefact}
Here we present some use-cases for interacting with artefacts in the network.

### Commenting on an existing artefact in the network ### {#uc-create-interaction-comment}
Bob has some questions over an artefact created in the network.
Bob opens the scholarly dashboard, and navigates to the artefact view.
Bob selects the option to add a new comment.
In the new comment view, Bob writes his comment and submits.
The dashboard stores the comment and the relevant data on Bob's data pod.
The scholarly dashboard retrieves the awareness and archiving service hub information (registering interactions is not necessary?).
The archiving service stores the comment and indexes it to be retrievable with the data for the original (multiple?) referenced artefact(s).
The awareness hub extracts the artefact(s) that are referenced by (in) the comment, and notifies all actors subscribed to these artefacts of a new interaction lifecycle event.
Here we present some use-cases for interacting with artefacts in the network.



## Subscribing to entities in the network ## {#uc-subscribing}
Actors in the network SHOULD be able to subscribe to artefact lifecycle events for artefacts in the network.
Additionally, actors MAY be able to subscribe to the events of new actors being added to the network.
Actors SHOULD be able to subscribe to only specific event types linked to specific artefacts (or actors), that can be filtered by the actor on the available dimensions of artefacts in the network.

## Subscribing to artefacts of a specific author in the network ## {#uc-subscribe-artefact}
Bob wishes to subscribe to all artefacts created by Alice in the network, to receive updates of all new lifecycle information of her artefacts.
Bob uses the scholarly dashboard and navigates to the subscription page.
The scholarly dashboard retrieves the awareness subscription hub information from the used orchestrator.
The subscription service hub advertises the available dimensions on which artefacts in the network can be filtered, and the available lifecycle information to which can be subscribed.
The scholarly dashboard represents these options to Bob.
Bob decides to filter the artefacts based on their author, and enters the webId of Alice into the filter.
Bob decides to subscribe to the "create" and "publish" lifecycle events.
On submission, the availability service hub saves the subscription, and on subsequent relevant lifecycle events of artefacts with Alice as the author, Bob receives a notification of these events.
The subscription is also stored with the necessary metadata on Bob's pod, allowing Bob to easily list and undo created subscriptions.

## Undo a specific subscription ## {#uc-unsubscribe-artefact}
Bob wishes to undo a specific subscription because of too much events.
Bob navigates to the subscription page of the scholarly dashboard.
All previous subscriptions are listed on the page.
Bob selects a subscription, and chooses the remove option.
The awareness service hub is notified that the specific subscription should be removed.
On success from the service hub, the scholarly dashboard removes the subscription from Bob's pod.


Requirements {#requirements}
================================================================================
In this section the requirements are listed based on the proposed architecture [[#architecture]] and use cases [[#usecases]].



## Data Storage ## {#rq-solid-storage}
To provide researchers with the possibility to store their own research artefacts and interactions, while keeping control of the data in the process, pod environments such as Solid can be used.
These can be hosted by the research institutions themselves, or by recommended third party services.

### Research Artefact Storage ### {#rq-artefact-storage}
Research artefacts (Papers, images, datasets, ...) can be stored as (non-)rdf documents on the data pod of the researcher, or can be linked to the data pod from an external sources using mechanics described in [[#rq-data-discovery]].

### Interaction artefacts storage ### {#rq-interaction-artefact-storage}
Research artefacts (Papers, images, datasets, ...) 
Publications can be stored as documents on the data pod of the researcher, or can be linked to the data pod from an external sources using mechanics described in [[#rq-data-discovery]].


### Metadata Storage ### {#rq-metadata-storage}
There are multiple solutions to store metadata for (non-)rdf data on a Linked Data Platform. However, it may benefit applications to support multiple approaches to metadata storage, and fall back on less ideal approaches in case the required metadata cannot be discovered.

#### .meta file #### {#meta-file}
A straightforward way to store file metadata on a Linked Data Platform is making use of a .meta file. As the .meta is a naming convention, for every file the .meta file can be automatically retrieved.
However, lately this seems to have been getting less and less traction in the community?

#### describedby / seeAlso metadata #### {#describedby}
Metadata can be provided in a more semantic way using predicates as ```rdf:seeAlso```.
This metadata can be stored in the location where the relevant resource is stored. 
A downside to this however is that if a resource is directly retrieved, this information will not be retrieved, and the metadata reference will be lost to the application retrieving the resource.

#### Link header #### {#link-seeAlso}
A third solution is to provide [Link Relations](https://www.w3.org/TR/ldp/#link-relation-describedby)
This solution returns the link to the metadata file in the response header of the HTTP request.
Using this solution in combination with the previous solution of providing the link to the metadata file in the RDF data where the resource is stored, provides the most complete approach to storing metadata for a resource.

### Data Discovery ### {#rq-data-discovery}
Data discovery is required for external services to retrieve artefacts from a researcher pod, on being notified of new data.
There should be a semantic way for external applications and services to discover the locations of certain types of artefacts and their metadata, and retrieve this data, given the correct permissions.
Currently, **shape trees** are considered as the go-to approach to enable data discovery on linked data platforms.

### Location aware data storage ### {#rq-location-aware-storage}
External services that need to post data to the researcher pod (e.g. registration service hub returning a certificate of registration) need to be aware of the location where they can post this data.
The **shape tree** approach used for data discovery can also be used to make the actor posting data aware of the location where data matching a given shape should be posted.

### Artefact versioning ### {#rq-artefact-versioning}
Versioning is a concept that is very relevant for scholarly communication, as certain artefacts (datasets, papers, ...) can be iterated upon (incorporating reviews, ...).
In order to support this behavior, a versioning system must be in place that allows for actors in the network to retrieve different versions of the same research publication.
This versioning system also should take into account the available lifecycle event information for the artefacts in question (Using the avialable lifecycle information, an actor in the network SHOULD be able construct the whole timeline of an artefact: creation, updates, publication, interactions, ...).
This concept could also be applied for interaction artefacts (e.g. see comments on proposed edits, see updates of made comments, ...)


### Permissions ### {#rq-permissions}
Permissions are an important tool for data pods to protect private information.
Only actors with the correct permissions set have access to resources in a pod environment.
In pod environments, permissions are handled using ACL files.

#### Setting permissions #### {#rq-set-permissions}
Functionality must be in place for all allowed to set permissions in a data pod.
This requires that researchers are able to allow e.g. a scholarly dashboard to edit the permissions of their data pod (for specific locations).

#### Group permissions #### {#req-group-permissions}
Setting permissions for individual actors can be insufficient at times.
Applications built on the Mellon framework SHOULD enable actors to to create, edit, and delete permissions for groups of actors.
Creating or updating a permission group MUST have the consequence that the permissions of this group are applied on the new permission group, and are removed from actors that are removed from the permission group.
This can be useful for e.g. creating a permissions group for your research group, so that permissions for created research can be automatically granted for the whole research group, instead of needing to set all permissions individually.



## Events ## {#rq-events}

### Notifications ### {#rq-notifications}
Notifications are required for the scholarly dashboard to notify the user of new information (received from e.g. the awareness service).

#### Notification filtering #### {#rq-notification-filtering}
A scholarly dashboard application SHOULD be able to filter notifications based on preset shapes.
This enables the scholarly dashboard to filter the notifiactions for relevant lifecycle information of searched artefacts.

#### Notification based actions #### {#rq-notification-based-actions}
In the case that notifications are used to notify of important artefact lifecycle information (in the case this is not directly posted to the researcher pod because of design reasons?), fucntionality is required that can evaluated the received notifications and execute automatic actions.
This can be avoided by making notifications non-essentialy by posting the important life cycle events directly to the data pod, and making the notifications secondary to this and only point out the locations of the newly added data.


## Policies ## {#rq-policy}
Functionality is required for actors to enforce policies on data being generated / submitted / ... in the network.

### Shape matching ### {#rq-policy-shapes}
Shape matching functionality is a vital part of enforcing policies for actors to match the shape of artefacts and their metadata in case of RDF data. 
Shape matching makes use of a shape ontology, for which both [shacl](https://www.w3.org/TR/shacl/) and [shex](https://shex.io/) are currently the most relevant shape ontologies.
In case of non-rdf data, other solutions may be required.


## Service hubs ## {#rq-service-hubs}
In this sections the requirements for the different service hubs are listed.

### Service hub discovery ### {#rq-service-discovery}
Service hubs in the network MUST be discoverable via advertisement of a service hub by orchestrators in the network.


### Service hub interactions ### {#rq-service-interactions}
Service hubs MUST advertise the specific services they provide.
Multiple service hubs may be used simultaneously to fulfil the same service (e.g. a researcher may register his created artefacts at multiple service hubs).

### Service hub functions ### {#rq-service-functions}
Here the different available services in the network are listed.
The proposed registration tokens are not bindingm and could be replaced by other verification mechanisms (see [[#rq-verification]]).

### Registration service ### {#rq-registration-service}
A registration service MUST provide a token of registration to the pod where the submitted artefact is stored. This token MUST be timestamped to allow actors in the network to verify claims of precedence.
A copy of this token (and the submitted artefact) MUST be stored locally, to allow for verification by actors in the network, and should be provided to an archiving service.

### Certification service ### {#rq-certification-service}
A certification service MUST compare a submitted artefact with the current *state-of-the-art* in the respective field.
If the submitted artefact is novel, the service MUST provide a certification token to the pod where the submitted artefact is stored.
A copy of this token (and the submitted artefact) MUST be stored locally, to allow for verification by actors in the network, and should be provided to an archiving service.


#### Peer review service #### {#rq-peer-review-service}
In the case of peer reviews, the a service may be setup that forwards a submitted artefact to a set of peers the network for review.
The reviews of these MUST be returned to the service (before a set deadline), where the service will return a token with the attached reviews.

### Awareness service ### {#rq-awareness-service}
The service MUST advertise the available dimensions of the artefacts on the network for which an actor can subscribe (e.g. title, tags, creator, ...).
Next to artefacts, an awareness service MAY also advertise new actors (researchers / service hubs / ...) connected to the network.
The service MUST provide an interface for actors in the network to subscribe to specific lifecycle events of artefacts that can be filtered on all advertised dimensions.
The awareness service MUST update all relevant subscribers of new information in the network.
The service MUST provide an interface to undo specific subscriptions.

### Archiving service ### {#rq-archiving-service}
An archiving service MUST store all submitted artefact data it receives.
The service MUST provide an interface to retrieve specific data from the service.

## Verification mechanics ## {#rq-verification}
A scholarly communication network requires a way for actors in the network to verify data and entities in the network.

### Researcher profile verification ### {#rq-profile-verification}
A method MUST be in place for actors to have their profile information verified by actors in the network. This requires an authority (in this case probably a research institution) to provide a token to the researcher pod that can be verified by a verification service provided by the institution.

### Artefact data verification ### {#rq-publication-verification}
An actor in the network MUST be able to verify an artefact in the network at the service hubs specified in the artefact metadata. E.g. An actor can verify the registration of the artefact by for example verifying a registration token available for the artefact at the registration service hub specified in the artefact metadata or lifecycle events.


## Ontologies ## {#ontology}
Thought should be given to what ontologies are to be used to semantically describe the artefacts and events. The use of different ontologies could mean that more or less compatibility layers are required for the framework to interact with different scholarly communication frameworks outside of its network.

Definitions {#definitions}
================================================================================

<!-- A <dfn>notification</dfn> is a distinct individual, group, organization, or piece of
software with an [=identity=] that can be strongly authenticated. -->

<pre class="biblio">
 {
<!--  "webid": {
    "href": "https://www.w3.org/2005/Incubator/webid/spec/identity/",
    "title": "WebID 1.0",
    "authors": [
      "Tim Berners-Lee",
      "Henry Story",
      "Andrei Sambra"
    ]
  },
  "did": {
    "href": "https://www.w3.org/TR/did-core/",
    "title": "Decentralized Identifiers (DIDs) v1.0",
    "authors": [
      "Drummond Reed",
      "Manu Sporney",
      "Dave Longley",
      "Christopher Allen",
      "Ryan Grant",
      "Markus Sabadello"
    ]
    }-->
  } 
</pre>